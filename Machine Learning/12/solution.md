K Nearest Neighbours or KNN is again one of the widely used supervised learning algorithms which is used for classification problems. It works in a way like you already know the coordinates of the point you wish to classify. Now you calculate the Manhattan/Euclidean Distance of the given point from all the points. Depending on the value of k, you select the nearest k neighbors and check their corresponding classes. The one which is in majority wins the race and the given point is classified into that particular class.

For example, the value of k is 3 and the nearest neighbors along with their classes are n1: Class 0, n2: Class 0 and n3: Class 1.  Since Class 0 is in majority, the given point will be classified as Class 0. Therefore it also answers why the value of k is not taken to be an even number. Quite simply, it is because the majority vote can be a tie case if the value of k is even.
