TF-IDF stands for Term-Frequency Inverse Document Frequency. It is a common method used in Information Retrieval and text mining. It is used to judge how relevant a term is concerning a document. Many times it happens that a word frequently occurs in a document but it is not relevant and not at all important to understand the meaning of the sentence or document. At the same time, the intuition behind the working of TF-IDF is that if the word occurs multiple times in a document, we should boost it’s relevance because it might be more meaningful to understand the context of the document. This is called Transfer Frequency. However, if the case is that the word occurs many time in the document but also among many other documents, this may be a frequent word and its significance might be less. This is called the IDF.

The relevance here means the amount of information the word should give about the sentence or the document if we humans were to understand the document without reading it fully.

Term frequency considers all words as equally important. Thus we cannot alone use term frequency to judge the weight or relevance of the word. There are certain stop words like if, the, a, etc which doesn’t affect the meaning of the sentence but are given equal importance by Term Frequency.  To solve this problem, we use IDF which uses logarithm to scale down this problem. The exact working of TF-IDF will be clear from the next question/example.
