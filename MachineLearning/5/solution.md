The cause of poor performance in a machine learning model is either over-fitting or under-fitting. Overfitting means when the model learns the details and noise in the model to such an extent that it negatively impacts the performance of the model. Due to this, the noise is picked up as a part of learning and the model tries to apply this learning to the new test cases. Since this is an unwanted type of data, hence, the result is flawed. We can understand this with the help of an example. Suppose there is a student who is preparing for his examination. He has practiced only certain types of questions for the test, say which involves only direct formulas. Now, when he attempts the test, he finds that the questions are different from what he has practiced. Quite naturally, he wouldnâ€™t be able to perform well in that test. This is because he has been trained or rather overfitted on a certain type of problem. When a new problem arises, he is not able to interpret it. The same is the case with machines. If they are trained on a single type of data or type of data which is mutually very common, it is called overfitting. Hence, it affects the performance of the model.
