The problem with non-convex cost function in Logistic Regression is that it suffers from the problem of local minima. Since it suffers from the problem of local minima, the gradient descent algorithm will have a hard time finding the global minima. The algorithm might wrongly label a local minima as global minima and can stop the training. Therefore, the accuracy will get compromised.
